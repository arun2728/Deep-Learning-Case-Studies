# -*- coding: utf-8 -*-
"""Customer_Churn_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QnkR8G4TQioH4LWcX8PMMHblNRafFKmx

# Artificial Neural Networks - Customer Churn
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

tf.__version__

"""## Step 1 - Data Preprocessing

### Import dataset
"""

raw_data = pd.read_csv('Churn_Modelling.csv')
X = raw_data.iloc[:,3:-1].values
y = raw_data.iloc[:,-1].values

X

X.shape

type(X)

y

y.shape

type(y)

"""### Checking for missing values"""

raw_data.info()

"""**We don't have any missing values**"""

# If your dataset have any missing values then we can remove them using imputer in sklearn package
#from sklearn.impute import SimpleImputer
#imputer = SimpleImputer(missing_values=np.nan,strategy="mean")
#imputer.fit(X[:,1:3])
#X[:,1:3] = imputer.transform()

"""### Encoding Categorical Data"""

raw_data.info()

"""**We can see that Geography and Gender are categorical in nature, So we will encode them**

#### For gender we will use label encoders
"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
le.fit(X[:,2])
X[:,2] = le.transform(X[:,2])

print(X)

"""We have succesfully encoded female into 0 and Male to 1

#### One-hot Encoding for Geography Column
"""

raw_data.Geography

raw_data.Geography.unique()

"""**Note: We have three different Geographic location so we will get three different columns when we One-hot encode 'Geography' column**"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')
X = np.array(ct.fit_transform(X))
print(X)

print(X.shape)

"""We can see that 'France' was encoded into '100', "Germany" into '010' and 'Spain' into '001'

### Split dataset into training and testing
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)

"""### Feature Scaling"""

# We scale all features irrespective of their data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

"""**End of Data Preprocessing**

---

## Step 2 - Building a ANN

### Intialize the ANN as sequence of layers
"""

ann = tf.keras.models.Sequential()

"""### Adding the input layer and first hidden layer"""

ann.add(tf.keras.layers.Dense(units=6,activation='relu')) # To add a layer to NN

"""### Adding the second hidden layer"""

ann.add(tf.keras.layers.Dense(units=6,activation='relu'))

"""### Adding the output layer

"""

ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))

"""## Step 3 - Training the ANN

### Compiling the ANN
"""

ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

"""### Training the ANN"""

ann.fit(X_train,y_train,batch_size=32,epochs=100)

"""## Part 4 - Making the predictions """

# For single test case
result = ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))
print(result > 0.5)

"""**Result is false so customer will not leave the bank**

**Important note 1**: Notice that the values of the features were all input in a double pair of square brackets. That's because the "predict" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.

**Important note 2:** Notice also that the "France" country was not input as a string in the last column but as "1, 0, 0" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, "France" was encoded as "1, 0, 0". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.

### Predicting the Test set results
"""

y_pred = ann.predict(X_test)
y_pred = (y_pred > 0.5)
print(y_pred)
print()
print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))

"""## Step 5 - Evaluating the model

#### Making Confusion Matrix
"""

from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test,y_pred)

conf_matrix = pd.DataFrame(data=cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])
# set sizeof the plot
plt.figure(figsize = (8,5))

# plot a heatmap
# cmap: colour code used for plotting
# annot: prints the correlation values in the chart
# annot_kws: sets the font size of the annotation
# cbar=False: Whether to draw a colorbar
# fmt: string formatting code to use when adding annotations
sns.heatmap(conf_matrix,annot=True,fmt='d',cmap='YlOrRd',cbar=False)
plt.show()
#accuracy_score(y_test,y_pred)

"""Classification Report"""

from sklearn.metrics import classification_report

class_report = classification_report(y_test,y_pred)
print(class_report)

"""ROC Curve"""

from sklearn.metrics import roc_curve, roc_auc_score
plt.rcParams['figure.figsize'] = (8,5)

fpr, tpr, thresholds = roc_curve(y_test,y_pred)

# plot the roc curve
plt.plot(fpr,tpr,'b-')

# Set limits
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.0])

# Plot a 45 deg line
plt.plot([0,1],[0,1],'r--')

# Add auc score
plt.text(x = 0.05, y = 0.8, s= ('AUC Score:', round(roc_auc_score(y_test,y_pred),4)))

# name of plot and axes
plt.xlabel('False positive rate(1 - Specificity)')
plt.ylabel('True positive rate(Sensitivity)')

# Plot grid
#plt.grid(True)
plt.show()

"""The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)

## Step 6 - Tabulate the result
"""

from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
cols = ['Model','AUC Score','Precision Score','Recall Score','Accuracy Score','f1-score']

result_tabulation = pd.DataFrame(columns = cols)

model_metrices = pd.Series({'Model' : 'ANN',
                            "AUC Score" : roc_auc_score(y_test,y_pred),
                            "Precision Score" : precision_score(y_test,y_pred),
                            "Recall Score" : recall_score(y_test,y_pred),
                            "Accuracy Score" : accuracy_score(y_test,y_pred),
                            "f1-score" : f1_score(y_test,y_pred)})
result_tabulation = result_tabulation.append(model_metrices,ignore_index=True)

result_tabulation

